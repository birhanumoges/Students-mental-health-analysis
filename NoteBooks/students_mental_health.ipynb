{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzc8AdT2Emnk"
      },
      "source": [
        "# students mental health Classification Notebook:\n",
        "This notebook loads data and prepares for analysis"
      ],
      "id": "jzc8AdT2Emnk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWMNrd-GEmnl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "print('Notebook loaded successfully')"
      ],
      "id": "JWMNrd-GEmnl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8YByr1vEmnl"
      },
      "outputs": [],
      "source": [
        "# Read the saved data\n",
        "print(\"=\" * 70)\n",
        "print(\"READING SAVED DATA\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv('processed_dataset2.csv')\n",
        "    print(f\"✅ Dataset loaded successfully!\")\n",
        "    print(f\" Shape: {df.shape}\")\n",
        "    print(f\" Columns: {len(df.columns)}\")\n",
        "    print(f\" Total records: {len(df)}\")\n",
        "except FileNotFoundError:\n",
        "    print(\" File 'processed_data.csv' not found.\")\n",
        "    exit()"
      ],
      "id": "V8YByr1vEmnl"
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# STUDENTS DATA PROCESSING\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"PROCESSING STUDENTS DATA\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "students_df = df[df[\"service_year_teacher\"].isnull()]\n",
        "print(f\"Initial students dataset shape: {students_df.shape}\")\n",
        "\n",
        "#----------------------------------------------------------------------\n",
        "# STEP 1: REMOVE NOT RELEVANT VARIABLES FOR STUDENTS\n",
        "#----------------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"STEP 1: REMOVING NOT RELEVANT VARIABLES FOR STUDENTS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "columns_to_drop = [\"service_year_teacher\", \"OSLO1\", \"OSLO2\", \"OSLO3\"]\n",
        "existing_drop_cols = [col for col in columns_to_drop if col in students_df.columns]\n",
        "\n",
        "if existing_drop_cols:\n",
        "    print(f\"Removed columns: {', '.join(existing_drop_cols)}\")\n",
        "    students_df = students_df.drop(columns=existing_drop_cols)\n",
        "    print(f\"✅ Dropped {len(existing_drop_cols)} irrelevant columns\")\n",
        "\n",
        "print(f\"Dataset shape: {students_df.shape}\")"
      ],
      "metadata": {
        "id": "lqbJUWhyFafZ"
      },
      "id": "lqbJUWhyFafZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#----------------------------------------------------------------------\n",
        "# STEP 2: FIRST CHECK NULL VALUES\n",
        "#----------------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"STEP 2: COMPREHENSIVE NULL VALUE CHECK\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "null_summary = students_df.isnull().sum()\n",
        "total_null_columns = (null_summary > 0).sum()\n",
        "total_null_values = null_summary.sum()\n",
        "\n",
        "print(f\"Total columns with null values: {total_null_columns}\")\n",
        "print(f\"Total null values in dataset: {total_null_values}\")\n",
        "\n",
        "if total_null_columns > 0:\n",
        "    null_analysis = []\n",
        "    null_columns_list = []\n",
        "    for col in students_df.columns:\n",
        "        null_count = students_df[col].isnull().sum()\n",
        "        if null_count > 0:\n",
        "            null_percentage = (null_count / len(students_df)) * 100\n",
        "            null_analysis.append({\n",
        "                'Column': col,\n",
        "                'Null_Count': null_count,\n",
        "                'Null_Percentage': null_percentage,\n",
        "                'Data_Type': students_df[col].dtype\n",
        "            })\n",
        "            null_columns_list.append(col)\n",
        "\n",
        "    print(f\"Columns with null values: {', '.join(null_columns_list)}\")\n",
        "    null_df = pd.DataFrame(null_analysis)\n",
        "else:\n",
        "    print(\"✅ No null values found\")\n",
        "\n",
        "#----------------------------------------------------------------------\n",
        "# STEP 3: REMOVE HIGH NULL VALUE COLUMNS\n",
        "#----------------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"STEP 3: REMOVING HIGH NULL VALUE COLUMNS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "high_missing_columns = ['Alcohol_2', 'Alcohol_3', 'Alcohol_4', 'Alcohol_5', 'Alcohol_6', 'alcohol_7',\n",
        "                       'tobaco_2', 'tobaco_3', 'tobaco_4', 'tobaco_5', 'tobaco_6', 'tobaco_7',\n",
        "                       'khat_2', 'khat_3', 'khat_4', 'khat_5', 'khat_6', 'khat_7']\n",
        "\n",
        "if 'null_df' in locals():\n",
        "    current_high_null_cols = null_df[null_df['Null_Percentage'] > 50]['Column'].tolist()\n",
        "    all_high_null_cols = list(set(high_missing_columns + current_high_null_cols))\n",
        "else:\n",
        "    all_high_null_cols = high_missing_columns\n",
        "\n",
        "existing_high_null_cols = [col for col in all_high_null_cols if col in students_df.columns]\n",
        "\n",
        "if existing_high_null_cols:\n",
        "    print(f\"Columns to remove: {', '.join(existing_high_null_cols)}\")\n",
        "    initial_cols = len(students_df.columns)\n",
        "    students_df = students_df.drop(columns=existing_high_null_cols)\n",
        "    final_cols = len(students_df.columns)\n",
        "    print(f\"✅ Removed {len(existing_high_null_cols)} high null columns\")\n",
        "else:\n",
        "    print(\"✅ No high null columns to remove\")\n",
        "\n",
        "print(f\"Current dataset shape: {students_df.shape}\")"
      ],
      "metadata": {
        "id": "0SxMydvIFziA"
      },
      "id": "0SxMydvIFziA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#----------------------------------------------------------------------\n",
        "# STEP 4: HANDLE REMAINING MISSING VALUES\n",
        "#----------------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"STEP 4: HANDLING REMAINING MISSING VALUES\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "remaining_null_summary = students_df.isnull().sum()\n",
        "remaining_null_summary = remaining_null_summary[remaining_null_summary > 0]\n",
        "\n",
        "if len(remaining_null_summary) > 0:\n",
        "    remaining_cols = list(remaining_null_summary.index)\n",
        "    print(f\"Columns with null values: {', '.join(remaining_cols)}\")\n",
        "\n",
        "    academic_cols = ['average', 'rank']\n",
        "    academic_cols_to_fill = [col for col in academic_cols if col in students_df.columns and students_df[col].isnull().sum() > 0]\n",
        "    if academic_cols_to_fill:\n",
        "        print(f\"Filling academic columns: {', '.join(academic_cols_to_fill)}\")\n",
        "        for col in academic_cols_to_fill:\n",
        "            students_df[col] = students_df[col].fillna(students_df[col].median())\n",
        "\n",
        "    substance_cols = ['Alcohol_1', 'tobaco_1', 'khat_1']\n",
        "    substance_cols_to_fill = [col for col in substance_cols if col in students_df.columns and students_df[col].isnull().sum() > 0]\n",
        "    if substance_cols_to_fill:\n",
        "        print(f\"Filling substance use columns: {', '.join(substance_cols_to_fill)}\")\n",
        "        for col in substance_cols_to_fill:\n",
        "            students_df[col] = students_df[col].fillna(students_df[col].median())\n",
        "\n",
        "    other_null_cols = [col for col in remaining_cols if col not in academic_cols + substance_cols]\n",
        "    if other_null_cols:\n",
        "        print(f\"Other columns with null values: {', '.join(other_null_cols)}\")\n",
        "        for col in other_null_cols:\n",
        "            if students_df[col].dtype in ['int64', 'float64']:\n",
        "                students_df[col] = students_df[col].fillna(students_df[col].median())\n",
        "            else:\n",
        "                mode_value = students_df[col].mode()[0] if len(students_df[col].mode()) > 0 else 'Unknown'\n",
        "                students_df[col] = students_df[col].fillna(mode_value)\n",
        "else:\n",
        "    print(\"✅ No remaining null values to handle\")"
      ],
      "metadata": {
        "id": "cTI-YrakGXyN"
      },
      "id": "cTI-YrakGXyN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#----------------------------------------------------------------------\n",
        "# STEP 5: CREATE AGGREGATED FEATURES AND REMOVE INDIVIDUAL ITEMS\n",
        "#----------------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"STEP 5: CREATING AGGREGATED FEATURES\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Create SRQ total score\n",
        "print(\"Creating SRQ_total (Mental Health Assessment)...\")\n",
        "srq_columns = [f'SRQ{i}' for i in range(1, 21)]\n",
        "existing_srq_cols = [col for col in srq_columns if col in students_df.columns]\n",
        "if existing_srq_cols:\n",
        "    srq_nulls = students_df[existing_srq_cols].isnull().sum().sum()\n",
        "    if srq_nulls == 0:\n",
        "        students_df['SRQ_total'] = students_df[existing_srq_cols].sum(axis=1)\n",
        "        print(f\"✅ Created SRQ_total from {len(existing_srq_cols)} SRQ items\")\n",
        "        print(f\" SRQ_total stats: Min={students_df['SRQ_total'].min()}, Max={students_df['SRQ_total'].max()}, Mean={students_df['SRQ_total'].mean():.2f}\")\n",
        "\n",
        "        # Remove individual SRQ columns\n",
        "        students_df = students_df.drop(columns=existing_srq_cols)\n",
        "        print(f\" Removed individual SRQ columns\")\n",
        "    else:\n",
        "        print(f\" SRQ columns have {srq_nulls} null values\")\n",
        "else:\n",
        "    print(\" No SRQ columns found\")\n",
        "\n",
        "# Create MPSS total score\n",
        "print(\"\\nCreating MPSS_total (Social Support Assessment)...\")\n",
        "mpss_columns = [f'MPSS{i}' for i in range(1, 13)]\n",
        "existing_mpss_cols = [col for col in mpss_columns if col in students_df.columns]\n",
        "if existing_mpss_cols:\n",
        "    mpss_nulls = students_df[existing_mpss_cols].isnull().sum().sum()\n",
        "    if mpss_nulls == 0:\n",
        "        students_df['MPSS_total'] = students_df[existing_mpss_cols].sum(axis=1)\n",
        "        print(f\"✅ Created MPSS_total from {len(existing_mpss_cols)} MPSS items\")\n",
        "        print(f\" MPSS_total stats: Min={students_df['MPSS_total'].min()}, Max={students_df['MPSS_total'].max()}, Mean={students_df['MPSS_total'].mean():.2f}\")\n",
        "\n",
        "        # Remove individual MPSS columns\n",
        "        students_df = students_df.drop(columns=existing_mpss_cols)\n",
        "        print(f\" Removed individual MPSS columns\")\n",
        "    else:\n",
        "        print(f\" MPSS columns have {mpss_nulls} null values\")\n",
        "else:\n",
        "    print(\" No MPSS columns found\")"
      ],
      "metadata": {
        "id": "b0MEYISQG-6J"
      },
      "id": "b0MEYISQG-6J",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#----------------------------------------------------------------------\n",
        "# FINAL VERIFICATION\n",
        "#----------------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"FINAL VERIFICATION\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "final_null_count = students_df.isnull().sum().sum()\n",
        "final_null_columns = (students_df.isnull().sum() > 0).sum()\n",
        "\n",
        "print(f\"Total null values: {final_null_count}\")\n",
        "print(f\"Columns with null values: {final_null_columns}\")\n",
        "\n",
        "if final_null_count == 0:\n",
        "    print(\"✅ Dataset is completely clean\")\n",
        "else:\n",
        "    remaining_nulls = students_df.isnull().sum()\n",
        "    remaining_nulls = remaining_nulls[remaining_nulls > 0]\n",
        "    remaining_cols = list(remaining_nulls.index)\n",
        "    print(f\"Remaining null columns: {', '.join(remaining_cols)}\")\n",
        "\n",
        "print(f\"\\nFINAL DATASET SUMMARY:\")\n",
        "print(f\"Shape: {students_df.shape}\")\n",
        "print(f\"Total records: {len(students_df)}\")\n",
        "print(f\"Total features: {len(students_df.columns)}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"STUDENTS DATA PROCESSING COMPLETED! ✅\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(\"\\nSAMPLE OF FINAL STUDENTS DATASET:\")\n",
        "print(students_df.head(3))"
      ],
      "metadata": {
        "id": "zKhgCdzgHLXI"
      },
      "id": "zKhgCdzgHLXI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CATEGORICAL ENCODING AND FEATURE SELECTION\n",
        "# =============================================================================\n",
        "print(\"=\" * 70)\n",
        "print(\"CATEGORICAL ENCODING AND FEATURE SELECTION\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(\"Initial dataset shape:\", students_df.shape)\n",
        "\n",
        "#----------------------------------------------------------------------\n",
        "# STEP 1: ENCODING CATEGORICAL VARIABLES\n",
        "#----------------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"STEP 1: ENCODING CATEGORICAL VARIABLES\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "\n",
        "students_encoded = students_df.copy()\n",
        "label_encoders = {}\n",
        "\n",
        "# One-Hot Encoding for school (nominal variable)\n",
        "print(\"One-Hot Encoding for school:\")\n",
        "school_dummies = pd.get_dummies(students_encoded['school'], prefix='school')\n",
        "students_encoded = pd.concat([students_encoded, school_dummies], axis=1)\n",
        "students_encoded = students_encoded.drop('school', axis=1)\n",
        "print(f\"Created {school_dummies.shape[1]} school dummy variables\")\n",
        "\n",
        "# Label Encoding for binary and ordinal variables\n",
        "categorical_columns = ['sex', 'Education', 'Alcohol_1', 'tobaco_1', 'khat_1']\n",
        "\n",
        "for col in categorical_columns:\n",
        "    if col in students_encoded.columns:\n",
        "        le = LabelEncoder()\n",
        "        students_encoded[col] = le.fit_transform(students_encoded[col].astype(str))\n",
        "        label_encoders[col] = le\n",
        "        print(f\"{col}: {dict(zip(le.classes_, le.transform(le.classes_)))}\")\n",
        "\n",
        "print(f\"Encoded dataset shape: {students_encoded.shape}\")\n",
        "\n",
        "#----------------------------------------------------------------------\n",
        "# STEP 2: TARGET VARIABLE PREPARATION\n",
        "#----------------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"STEP 2: TARGET VARIABLE PREPARATION\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Regression target\n",
        "print(\"REGRESSION TARGET: SRQ_total\")\n",
        "\n",
        "# Classification target\n",
        "srq_median = students_encoded['SRQ_total'].median()\n",
        "students_encoded['SRQ_total_binary'] = (students_encoded['SRQ_total'] > srq_median).astype(int)\n",
        "\n",
        "print(\"CLASSIFICATION TARGET: SRQ_total_binary\")\n",
        "print(f\"Threshold: SRQ_total > {srq_median}\")\n",
        "class_dist = students_encoded['SRQ_total_binary'].value_counts()\n",
        "print(f\"Class 0: {class_dist[0]}, Class 1: {class_dist[1]}\")\n",
        "\n",
        "#----------------------------------------------------------------------\n",
        "# STEP 3: FEATURE SELECTION FOR REGRESSION\n",
        "#----------------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"STEP 3: FEATURE SELECTION FOR REGRESSION\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "regression_features = [col for col in students_encoded.columns\n",
        "                      if col not in ['ID', 'SRQ_total', 'SRQ_total_binary']]\n",
        "X_reg = students_encoded[regression_features]\n",
        "y_reg = students_encoded['SRQ_total']"
      ],
      "metadata": {
        "id": "D637kaI_eyw2"
      },
      "id": "D637kaI_eyw2",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}